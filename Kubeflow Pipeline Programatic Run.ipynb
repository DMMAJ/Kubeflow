{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf80aa68-3c60-4175-8f4c-5f86edbed883",
   "metadata": {},
   "source": [
    "# Kubeflow Pipeline Programatic Run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e618be-6aac-4908-93bb-b67c5ce31f4b",
   "metadata": {},
   "source": [
    "## Exemplary Pipeline for Decision Tree :\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6782fa72-b514-46d6-914d-bf4db8b95325",
   "metadata": {},
   "source": [
    "### Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f125e76-ffca-4a46-a58b-330b5dd7311f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp.components as comp\n",
    "\n",
    "# Passes output to preprocess_data\n",
    "\n",
    "def load_data(output_data_path: comp.OutputPath(str)):\n",
    "    import pandas as pd\n",
    "    import os\n",
    "    print(\"----- Inside load_data component -----\")\n",
    "\n",
    "    # Importing the Social Netwrok Ads data from github repository\n",
    "    df = pd.read_csv('https://github.com/anshul1004/DecisionTree/blob/master/data_set/Social_Network_Ads.csv?raw=true')\n",
    "    df.drop(columns='User ID', inplace = True)\n",
    "    print(df)\n",
    "\n",
    "    os.makedirs(output_data_path, exist_ok=True)\n",
    "    df.to_csv(f'{output_data_path}/df.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0a0dd4-2ebd-4242-b44d-99164b853b7d",
   "metadata": {},
   "source": [
    "### Preprocessing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9feda8b-f356-493e-a5db-53a787b09642",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp.components as components\n",
    "\n",
    "# Takes input from load_data and passes output to train_model & evaluate_model\n",
    "\n",
    "def preprocess_data(preprocessed_data_path: comp.OutputPath(str), output_data_path: comp.InputPath(str)):\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import category_encoders as ce\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    import os\n",
    "    \n",
    "    print(\"----- Inside preprocess_data component -----\")\n",
    "\n",
    "    df = pd.read_csv(f'{output_data_path}/df.csv')\n",
    "\n",
    "    # Last column of the dataframe is the target class\n",
    "    X = df.drop([df.columns[-1]], axis=1)  \n",
    "    y = df[df.columns[-1]]\n",
    "\n",
    "    # We can utilise encoder from scikit-learn as well\n",
    "    encoder = ce.OrdinalEncoder(cols=X.columns.tolist())\n",
    "    X_enc = encoder.fit_transform(X)\n",
    "    print(X_enc)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_enc, y, test_size=0.33, random_state=42)\n",
    "    print(X, y, X_train, X_test, y_train, y_test)\n",
    "\n",
    "    os.makedirs(preprocessed_data_path, exist_ok=True)\n",
    "    np.save(f'{preprocessed_data_path}/X_train.npy', X_train)\n",
    "    np.save(f'{preprocessed_data_path}/X_test.npy', X_test)\n",
    "    np.save(f'{preprocessed_data_path}/y_train.npy', y_train)\n",
    "    np.save(f'{preprocessed_data_path}/y_test.npy', y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea6340d-30c7-43cf-b3da-e099a9aa7bb1",
   "metadata": {},
   "source": [
    "### Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e716b037-4e48-4004-b10f-fae5718a5038",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp.components as components\n",
    "\n",
    "# Takes input from preprocess_data and passes output to evaluate_model\n",
    "\n",
    "def train_model(preprocessed_data_path: comp.InputPath(str), trained_model_path: comp.OutputPath(str)):\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    import pickle\n",
    "    import numpy as np\n",
    "    import os\n",
    "    print(\"----- Inside train_model component -----\")\n",
    "    \n",
    "    X_train = np.load(f'{preprocessed_data_path}/X_train.npy',allow_pickle=True)\n",
    "    y_train = np.load(f'{preprocessed_data_path}/y_train.npy',allow_pickle=True)\n",
    "\n",
    "    # Using \"entropy\" index, can also go with \"gini\" index \n",
    "    criterion='entropy'\n",
    "    max_depth=3\n",
    "    random_state=0\n",
    "    \n",
    "    clf = DecisionTreeClassifier(criterion=criterion, max_depth=max_depth, random_state=random_state)\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    os.makedirs(trained_model_path, exist_ok=True)\n",
    "    with open(f'{trained_model_path}/model.pkl', 'wb') as f:\n",
    "        pickle.dump(clf, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f40fd2-1ac7-444d-ba8e-b62ad7a96878",
   "metadata": {},
   "source": [
    "### Evaluating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7158f376-78f5-4ca2-930a-e661d58b0083",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp.components as components\n",
    "\n",
    "# Takes inputs from preprocess_data and train_model\n",
    "\n",
    "def evaluate_model(trained_model_path: comp.InputPath(str), preprocessed_data_path: comp.InputPath(str), evaluated_model_path: comp.OutputPath(str)):\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    import pickle\n",
    "    import numpy as np\n",
    "    import os\n",
    "    print(\"----- Inside evaluate_model component -----\")\n",
    "\n",
    "    with open(f'{trained_model_path}/model.pkl', 'rb') as f:\n",
    "        clf = pickle.load(f)\n",
    "    X_test = np.load(f'{preprocessed_data_path}/X_test.npy',allow_pickle=True)\n",
    "    y_test = np.load(f'{preprocessed_data_path}/y_test.npy',allow_pickle=True)\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(accuracy)\n",
    "    # We can also plot the output(y_pred) wrt test data for visualisation...\n",
    "    \n",
    "    os.makedirs(evaluated_model_path, exist_ok=True)\n",
    "    np.save(f'{evaluated_model_path}/y_pred.npy', y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a21f33-f87f-4169-b43a-776675c264e3",
   "metadata": {},
   "source": [
    "### Creating Components of Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0caeab-5d27-4b35-bab1-84dba373c96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp\n",
    "\n",
    "BASE_IMAGE = 'tensorflow/tensorflow:2.11.1'\n",
    "PACKAGES = ['pandas','numpy','scikit-learn', 'category_encoders']\n",
    "\n",
    "# All four functions being transformed into pipeline components with same package for simplicity\n",
    "create_step_load_data = kfp.components.create_component_from_func(\n",
    "    func=load_data,\n",
    "    base_image=BASE_IMAGE,\n",
    "    packages_to_install=PACKAGES\n",
    ")\n",
    "\n",
    "create_step_preprocess_data = kfp.components.create_component_from_func(\n",
    "    func=preprocess_data,\n",
    "    base_image=BASE_IMAGE,\n",
    "    packages_to_install=PACKAGES\n",
    ")\n",
    "\n",
    "create_step_train_model = kfp.components.create_component_from_func(\n",
    "    func=train_model,\n",
    "    base_image=BASE_IMAGE,\n",
    "    packages_to_install=PACKAGES\n",
    ")\n",
    "\n",
    "create_step_evaluate_model = kfp.components.create_component_from_func(\n",
    "    func=evaluate_model,\n",
    "    base_image=BASE_IMAGE,\n",
    "    packages_to_install=PACKAGES\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520ba380-5e88-4daa-ae70-7546b63ffe02",
   "metadata": {},
   "source": [
    "### Defining the Pipeline Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55255168-7fa1-490f-961c-e7ccffa55467",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp.dsl as dsl\n",
    "\n",
    "data_path = '/decision_tree' # It is to just pass an argument or we can remove argument from pipeline definition\n",
    "\n",
    "@dsl.pipeline(\n",
    "   name='Decision Tree Classifier Pipeline',\n",
    "   description='A pipeline that trains and evaluates a decision tree classifier.'\n",
    ")\n",
    "\n",
    "def decision_tree_pipeline(data_path: (str)):\n",
    "    \n",
    "    load_data_path = create_step_load_data()\n",
    "    \n",
    "    preprocessed_data_path = create_step_preprocess_data(load_data_path.output)\n",
    "    \n",
    "    trained_model_path = create_step_train_model(preprocessed_data_path.output)\n",
    "    \n",
    "    evaluated_model_path = create_step_evaluate_model(trained_model_path.output, preprocessed_data_path.output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4226c3a-db09-43d6-b684-88f0c6334b7b",
   "metadata": {},
   "source": [
    "### Creating a Kubeflow Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa8e7de-ca4b-491b-9d66-7f968300b651",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp\n",
    "import requests\n",
    "from datetime import datetime\n",
    "\n",
    "KUBEFLOW_ENDPOINT = \" \" # mention your kubeflow endpoint url\n",
    "PROFILE_USERNAME = \" \" # kubeflow account username\n",
    "PROFILE_PASSWORD = \" \" # kubeflow account password\n",
    "PROFILE_NAMESPACE = \" \" # the namespace in which you want to run the pipeline\n",
    "\n",
    "# Function to generate cookie to make a client\n",
    "# It requires login details of the kubeflow account\n",
    "def get_auth_session_cookie(host, login, password):\n",
    "    session = requests.Session()\n",
    "    response = session.get(host)\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/x-www-form-urlencoded\",\n",
    "    }\n",
    "    data = {\"login\": login, \"password\": password}\n",
    "    session.post(response.url, headers=headers, data=data)\n",
    "    session_cookie = session.cookies.get_dict()[\"authservice_session\"]\n",
    "    return session_cookie\n",
    "\n",
    "session_cookie = get_auth_session_cookie(\n",
    "      KUBEFLOW_ENDPOINT, PROFILE_USERNAME, PROFILE_PASSWORD\n",
    ")\n",
    "print(f\"retrieved cookie: {session_cookie}\")\n",
    "\n",
    "# Creating kubeflow client to access kubeflow services\n",
    "kfp_client = kfp.Client(host=f\"{KUBEFLOW_ENDPOINT}/pipeline\", cookies=f\"authservice_session={session_cookie}\", namespace=PROFILE_NAMESPACE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff514ce-b15b-4bae-843b-6c5100e7c92a",
   "metadata": {},
   "source": [
    "### Client Services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827e259f-eb3d-44c6-a6e0-847d8ccb9686",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an experiment\n",
    "exp_name = datetime.now().strftime(\"%Y-%m-%d-%H-%M\")\n",
    "experiment = kfp_client.create_experiment(name=f\"demo-{exp_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac605d47-b6f0-4dac-8def-e856d67e1a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a run\n",
    "from kfp import compiler\n",
    "compiler.Compiler().compile(decision_tree_pipeline, package_path='decision_tree/decision_tree_pipeline.yaml')\n",
    "\n",
    "# By the Pipeline Function\n",
    "kfp_client.create_run_from_pipeline_func(decision_tree_pipeline, arguments={'data_path': '/decision_tree'})\n",
    "\n",
    "# By the YAML file\n",
    "kfp_client.create_run_from_pipeline_package('decision_tree_pipeline.yaml', arguments={'data_path': '/decision_tree'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203d185c-885e-4801-b450-7d5cb2a55ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running the pipeline\n",
    "\n",
    "# kfp_client.list_experiments()\n",
    "# kfp_client.list_pipelines()\n",
    "# kfp_client.list_runs()\n",
    "\n",
    "pip = \" \" # mention pipeline id\n",
    "exp = \" \" # mention experiment id\n",
    "kfp_client.run_pipeline(experiment_id=exp, pipeline_id=pip, params={'data_path': '/decision_tree'}, job_name=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d420d6f-c8a4-43ca-941b-a915e50ea14b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
